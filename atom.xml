<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Yz21.github.io/</id>
    <title>Gridea</title>
    <updated>2019-08-13T01:06:39.087Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Yz21.github.io/"/>
    <link rel="self" href="https://Yz21.github.io//atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://Yz21.github.io//images/avatar.png</logo>
    <icon>https://Yz21.github.io//favicon.ico</icon>
    <rights>All rights reserved 2019, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[浅谈机器学习-分类和聚类的区别]]></title>
        <id>https://Yz21.github.io//post/浅谈机器学习-分类和聚类的区别</id>
        <link href="https://Yz21.github.io//post/浅谈机器学习-分类和聚类的区别">
        </link>
        <updated>2019-07-31T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        机器学习中有两类的大问题，一个是分类，一个是聚类。在我们的生活中，我们常常没有过多的去区分这两个概念，觉得聚类就是分类，分类也差不多就是聚类，下面，我们就具体来研究下分类与聚类之间在数据挖掘中本质的区别。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        机器学习中有两类的大问题，一个是分类，一个是聚类。在我们的生活中，我们常常没有过多的去区分这两个概念，觉得聚类就是分类，分类也差不多就是聚类，下面，我们就具体来研究下分类与聚类之间在数据挖掘中本质的区别。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[浅谈机器学习-回归与分类的区别]]></title>
        <id>https://Yz21.github.io//post/浅谈机器学习-回归与分类的区别</id>
        <link href="https://Yz21.github.io//post/浅谈机器学习-回归与分类的区别">
        </link>
        <updated>2019-07-31T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        机器学习的主要任务便是聚焦于两个问题：分类和回归。本文将浅谈下两者的区别。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        机器学习的主要任务便是聚焦于两个问题：分类和回归。本文将浅谈下两者的区别。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[人工神经网络（ANN）]]></title>
        <id>https://Yz21.github.io//post/人工神经网络（ANN）</id>
        <link href="https://Yz21.github.io//post/人工神经网络（ANN）">
        </link>
        <updated>2019-07-25T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>        初学人工智能不久，今天碰上了人工神经网（ANN），开始学的时候很懵，一大堆理论、公式、推导.....作为一名小白，还是很痛苦的，不过经过摸索，大概了 解了什么是ANN，公式的推导以及一些其他问题，下面我就总结下自己的理解，一方面作为自己的笔记，日后方便巩固；另一方面，也可以分享给其他有意者。</p>
]]></summary>
        <content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>        初学人工智能不久，今天碰上了人工神经网（ANN），开始学的时候很懵，一大堆理论、公式、推导.....作为一名小白，还是很痛苦的，不过经过摸索，大概了 解了什么是ANN，公式的推导以及一些其他问题，下面我就总结下自己的理解，一方面作为自己的笔记，日后方便巩固；另一方面，也可以分享给其他有意者。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多种相似度计算的python实现]]></title>
        <id>https://Yz21.github.io//post/多种相似度计算的python实现</id>
        <link href="https://Yz21.github.io//post/多种相似度计算的python实现">
        </link>
        <updated>2019-07-23T16:00:00.000Z</updated>
    </entry>
    <entry>
        <title type="html"><![CDATA[推荐系统之矩阵分解(MF)及其python实现]]></title>
        <id>https://Yz21.github.io//post/推荐系统之矩阵分解(MF)及其python实现</id>
        <link href="https://Yz21.github.io//post/推荐系统之矩阵分解(MF)及其python实现">
        </link>
        <updated>2019-07-22T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        目前推荐系统中用的最多的就是矩阵分解方法，在Netflix Prize推荐系统大赛中取得突出效果。以用户-项目评分矩阵为例，矩阵分解就是预测出评分矩阵中的缺失值，然后根据预测值以某种方式向用户推荐。今天以“用户-项目评分矩阵R（M×N）”说明矩阵分解方式的原理以及python实现。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        目前推荐系统中用的最多的就是矩阵分解方法，在Netflix Prize推荐系统大赛中取得突出效果。以用户-项目评分矩阵为例，矩阵分解就是预测出评分矩阵中的缺失值，然后根据预测值以某种方式向用户推荐。今天以“用户-项目评分矩阵R（M×N）”说明矩阵分解方式的原理以及python实现。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[暑期培训第一次测试题总结]]></title>
        <id>https://Yz21.github.io//post/暑期培训第一次测试题总结</id>
        <link href="https://Yz21.github.io//post/暑期培训第一次测试题总结">
        </link>
        <updated>2019-07-21T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>这里是一些暑期培训第一次测试题的部分解释，经过这次测试的摧残，总结备录一下，方便日后回顾复习。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>这里是一些暑期培训第一次测试题的部分解释，经过这次测试的摧残，总结备录一下，方便日后回顾复习。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[KNN算法及python实现]]></title>
        <id>https://Yz21.github.io//post/K-最近邻分类算法(KNN)及python实现</id>
        <link href="https://Yz21.github.io//post/K-最近邻分类算法(KNN)及python实现">
        </link>
        <updated>2019-07-19T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        KNN算法即K-Nearest Neighbor，也是机器学习十大经典算法之一。前文讲解了K-means算法，今天我们就继续讲KNN算法，两者看起来挺相似的，但区别还是很大的，看完本片文章你就会明白了。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        KNN算法即K-Nearest Neighbor，也是机器学习十大经典算法之一。前文讲解了K-means算法，今天我们就继续讲KNN算法，两者看起来挺相似的，但区别还是很大的，看完本片文章你就会明白了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K-means算法及python实现]]></title>
        <id>https://Yz21.github.io//post/K-means聚类算法原理及python实现</id>
        <link href="https://Yz21.github.io//post/K-means聚类算法原理及python实现">
        </link>
        <updated>2019-07-18T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        K-means(Thek-meansalgorithm)是机器学习十大经典算法之一，同时也是最为经典的无监督聚类（Unsupervised Clustering）算法。接触聚类算法，首先需要了解k-means算法的实现原理和步骤。本文将对k-means算法的基本原理和实现实例进行分析。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        K-means(Thek-meansalgorithm)是机器学习十大经典算法之一，同时也是最为经典的无监督聚类（Unsupervised Clustering）算法。接触聚类算法，首先需要了解k-means算法的实现原理和步骤。本文将对k-means算法的基本原理和实现实例进行分析。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数据集的划分--训练集、验证集和测试集]]></title>
        <id>https://Yz21.github.io//post/数据集的划分--训练集、验证集和测试集</id>
        <link href="https://Yz21.github.io//post/数据集的划分--训练集、验证集和测试集">
        </link>
        <updated>2019-07-17T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        在机器学习中，经常提到训练集和测试集，验证集似有似无。感觉挺好奇的，就仔细查找了文献。以下谈谈训练集、验证集和测试集。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        在机器学习中，经常提到训练集和测试集，验证集似有似无。感觉挺好奇的，就仔细查找了文献。以下谈谈训练集、验证集和测试集。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[梯度下降法的三种形式BGD、SGD、MBGD及python实现]]></title>
        <id>https://Yz21.github.io//post/梯度下降法的三种形式BGD、SGD、MBGD及python实现</id>
        <link href="https://Yz21.github.io//post/梯度下降法的三种形式BGD、SGD、MBGD及python实现">
        </link>
        <updated>2019-07-17T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        梯度下降法作为机器学习中较常使用的优化算法，其有着三种不同的形式：批量梯度下降（Batch Gradient Descent）、随机梯度下降（Stochastic Gradient Descent）以及小批量梯度下降（Mini-Batch Gradient Descent）。其中小批量梯度下降法也常用在深度学习中进行模型的训练。接下来，我们将对这三种不同的梯度下降法进行理解。</p>
]]></summary>
        <content type="html"><![CDATA[<meta name="referrer" content="no-referrer" />
<h1 id="前言">前言</h1>
<p>        梯度下降法作为机器学习中较常使用的优化算法，其有着三种不同的形式：批量梯度下降（Batch Gradient Descent）、随机梯度下降（Stochastic Gradient Descent）以及小批量梯度下降（Mini-Batch Gradient Descent）。其中小批量梯度下降法也常用在深度学习中进行模型的训练。接下来，我们将对这三种不同的梯度下降法进行理解。</p>
]]></content>
    </entry>
</feed>